{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-way and two-way ANOVA (Part I)<a href=\"#One-way-and-two-way-ANOVA-(Part-I)\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "Throughout the following exercises, you will learn to use Python to run\n",
    "both a one-way and two-way ANOVA test. You'll also learn to run a post\n",
    "hoc test to analyze the results of a one-way ANOVA test. Before starting\n",
    "on this programming exercise, we strongly recommend watching the video\n",
    "lecture and completing the IVQ for the associated topics.\n",
    "\n",
    "Recall the following definitions:\n",
    "\n",
    "-   **One-way ANOVA:** Compares the means of one continuous dependent\n",
    "    variable based on three or more groups of one categorical variable.\n",
    "-   **Two-way ANOVA:** Compares the means of one continuous dependent\n",
    "    variable based on three or more groups of two categorical variables.\n",
    "\n",
    "All the information you need for solving this assignment is in this\n",
    "notebook, and all the code you will be implementing will take place\n",
    "within this notebook.\n",
    "\n",
    "As we move forward, you can find instructions on how to install required\n",
    "libraries as they arise in this notebook. Before we begin with the\n",
    "exercises and analyzing the data, we need to import all libraries and\n",
    "extensions required for this programming exercise. Throughout the\n",
    "course, we will be using pandas and statsmodels for operations, and\n",
    "seaborn for plotting.\n",
    "\n",
    "## Relevant Imports<a href=\"#Relevant-Imports\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "Begin by importing the relevant packages and data.\n",
    "\n",
    "In \\[1\\]:\n",
    "\n",
    "    # Import pandas and seaborn packages\n",
    "    import pandas as pd\n",
    "    import seaborn as sns\n",
    "\n",
    "In \\[2\\]:\n",
    "\n",
    "    # Load in diamonds data set from seaborn package\n",
    "    diamonds = sns.load_dataset(\"diamonds\", cache=False)\n",
    "\n",
    "    # Examine first 5 rows of data set\n",
    "    diamonds.head()\n",
    "\n",
    "Out\\[2\\]:\n",
    "\n",
    "|     | carat | cut     | color | clarity | depth | table | price | x    | y    | z    |\n",
    "|-----|-------|---------|-------|---------|-------|-------|-------|------|------|------|\n",
    "| 0   | 0.23  | Ideal   | E     | SI2     | 61.5  | 55.0  | 326   | 3.95 | 3.98 | 2.43 |\n",
    "| 1   | 0.21  | Premium | E     | SI1     | 59.8  | 61.0  | 326   | 3.89 | 3.84 | 2.31 |\n",
    "| 2   | 0.23  | Good    | E     | VS1     | 56.9  | 65.0  | 327   | 4.05 | 4.07 | 2.31 |\n",
    "| 3   | 0.29  | Premium | I     | VS2     | 62.4  | 58.0  | 334   | 4.20 | 4.23 | 2.63 |\n",
    "| 4   | 0.31  | Good    | J     | SI2     | 63.3  | 58.0  | 335   | 4.34 | 4.35 | 2.75 |\n",
    "\n",
    "## Data cleaning I (not shown in video)<a href=\"#Data-cleaning-I-(not-shown-in-video)\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "For this part of the course, our main focus is on one-way and two-way\n",
    "ANOVA. This means that our dataset needs a continuous variable, and up\n",
    "to two categorical variables.\n",
    "\n",
    "**Note:** In the workplace, you will always start with a business\n",
    "problem and the data, and then determine the best models or tests to run\n",
    "on the data. You will *never* work in the reverse. For educational\n",
    "purposes, our goal is to teach you about ANOVA in this notebook and the\n",
    "accompanying resources.\n",
    "\n",
    "In \\[3\\]:\n",
    "\n",
    "    # Check how many diamonds are each color grade\n",
    "    diamonds[\"color\"].value_counts()\n",
    "\n",
    "Out\\[3\\]:\n",
    "\n",
    "    G    11292\n",
    "    E     9797\n",
    "    F     9542\n",
    "    H     8304\n",
    "    D     6775\n",
    "    I     5422\n",
    "    J     2808\n",
    "    Name: color, dtype: int64\n",
    "\n",
    "In \\[4\\]:\n",
    "\n",
    "    # Subset for colorless diamonds\n",
    "    colorless = diamonds[diamonds[\"color\"].isin([\"E\",\"F\",\"H\",\"D\",\"I\"])]\n",
    "\n",
    "    # Select only color and price columns, and reset index\n",
    "    colorless = colorless[[\"color\",\"price\"]].reset_index(drop=True)\n",
    "\n",
    "**Note:** We took a subset of colorless and near colorless diamonds. We\n",
    "excluded G color grade diamonds as there were many more of them, and we\n",
    "excluded J color grade diamonds as there were significantly fewer of\n",
    "them. In a workplace setting, you would typically go through a more\n",
    "thoughtful process of subsetting. The goal of this notebook is focusing\n",
    "on ANOVA, not data cleaning or variable selection.\n",
    "\n",
    "In \\[5\\]:\n",
    "\n",
    "    # Remove dropped categories of diamond color\n",
    "    colorless.color = colorless.color.cat.remove_categories([\"G\",\"J\"])\n",
    "\n",
    "    # Check that the dropped categories have been removed\n",
    "    colorless[\"color\"].values\n",
    "\n",
    "Out\\[5\\]:\n",
    "\n",
    "    ['E', 'E', 'E', 'I', 'I', ..., 'D', 'D', 'D', 'H', 'D']\n",
    "    Length: 39840\n",
    "    Categories (5, object): ['D', 'E', 'F', 'H', 'I']\n",
    "\n",
    "In \\[6\\]:\n",
    "\n",
    "    # Import math package\n",
    "    import math\n",
    "\n",
    "    # Take the logarithm of the price, and insert it as the third column\n",
    "    colorless.insert(2, \"log_price\", [math.log(price) for price in colorless[\"price\"]])\n",
    "\n",
    "**Note:** The first argument in the `insert()` function allows you to\n",
    "specify the location of the new column with a column number. But the\n",
    "argument starts counting at 0. So if you put in 0, that is the first\n",
    "column; if you enter 1, that is the second column, and so on. Since we\n",
    "specified 2, the new `log_price` column will be the third column.\n",
    "\n",
    "Next, we use the `dropna()` function to drop the rows with missing\n",
    "values. Setting the `inplace` argument to `True` means that we do not\n",
    "have to save the dataframe as a new variable. Then, we'll reset the\n",
    "index using the `reset_index()` function to reset the index column to\n",
    "account for the rows we just dropped. The `inplace` argument works the\n",
    "same as it did for the `dropna()` function, and the `drop` argument\n",
    "prevents us from creating a new column with the old index numbers\n",
    "preserved.\n",
    "\n",
    "In \\[7\\]:\n",
    "\n",
    "    # Drop rows with missing values\n",
    "    colorless.dropna(inplace=True)\n",
    "\n",
    "    # Reset index\n",
    "    colorless.reset_index(inplace=True, drop=True)\n",
    "\n",
    "In \\[8\\]:\n",
    "\n",
    "    # Examine first 5 rows of cleaned data set\n",
    "    colorless.head()\n",
    "\n",
    "Out\\[8\\]:\n",
    "\n",
    "|     | color | price | log_price |\n",
    "|-----|-------|-------|-----------|\n",
    "| 0   | E     | 326   | 5.786897  |\n",
    "| 1   | E     | 326   | 5.786897  |\n",
    "| 2   | E     | 327   | 5.789960  |\n",
    "| 3   | I     | 334   | 5.811141  |\n",
    "| 4   | I     | 336   | 5.817111  |\n",
    "\n",
    "In \\[9\\]:\n",
    "\n",
    "    # Save to diamonds.csv\n",
    "    colorless.to_csv('diamonds.csv',index=False,header=list(colorless.columns))\n",
    "\n",
    "**Note:** The code creates a new .csv file of the `colorless` dataframe,\n",
    "and names it `diamonds.csv`. The `index` argument tells the function\n",
    "whether or not we want to save the index column as a column in the .csv\n",
    "file. Additionally, the `header` argument tells the function what the\n",
    "names of the columns should be.\n",
    "\n",
    "## One-way ANOVA<a href=\"#One-way-ANOVA\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "To run one-way ANOVA, we first load in the data, and save it as a\n",
    "variable called `diamonds`, and then examine it using the `head()`\n",
    "function.\n",
    "\n",
    "In \\[10\\]:\n",
    "\n",
    "    # Save diamonds.csv as a variable called diamonds\n",
    "    diamonds = pd.read_csv(\"diamonds.csv\")\n",
    "\n",
    "In \\[11\\]:\n",
    "\n",
    "    # Examine first 5 rows of diamonds data set\n",
    "    diamonds.head()\n",
    "\n",
    "Out\\[11\\]:\n",
    "\n",
    "|     | color | price | log_price |\n",
    "|-----|-------|-------|-----------|\n",
    "| 0   | E     | 326   | 5.786897  |\n",
    "| 1   | E     | 326   | 5.786897  |\n",
    "| 2   | E     | 327   | 5.789960  |\n",
    "| 3   | I     | 334   | 5.811141  |\n",
    "| 4   | I     | 336   | 5.817111  |\n",
    "\n",
    "Recall that one-way ANOVA helps us better understand the relationship\n",
    "between a categorical variable and a continuous variable. We'll do some\n",
    "basic exploratory data analysis by creating a boxplot using the\n",
    "`boxplot()` function from the `seaborn` package.\n",
    "\n",
    "Based on the plot, we can observe that there is a lot of overlap in the\n",
    "distribution of `log_price` for each color of diamond. But we can't tell\n",
    "yet if they are statistically significantly different.\n",
    "\n",
    "In \\[12\\]:\n",
    "\n",
    "    # Create boxplot to show distribution of price by color grade\n",
    "    sns.boxplot(x = \"color\", y = \"log_price\", data = diamonds)\n",
    "\n",
    "Out\\[12\\]:\n",
    "\n",
    "    <matplotlib.axes._subplots.AxesSubplot at 0x7f3f176b9e10>\n",
    "\n",
    "![](data:image/png;base64,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%0A)\n",
    "\n",
    "In order to run ANOVA, we need to create a regression model. To do this,\n",
    "we'll import the `statsmodels.api` package and the `ols()` function.\n",
    "Next, we'll create a simple linear regression model where the X variable\n",
    "is `color`, which we will code as categorical using `C()`. Then, we'll\n",
    "fit the model to the data, and generate model summary statistics.\n",
    "\n",
    "In \\[13\\]:\n",
    "\n",
    "    # Import statsmodels and ols function\n",
    "    import statsmodels.api as sm\n",
    "    from statsmodels.formula.api import ols\n",
    "\n",
    "In \\[14\\]:\n",
    "\n",
    "    # Construct simple linear regression model, and fit the model\n",
    "    model = ols(formula = \"log_price ~ C(color)\", data = diamonds).fit()\n",
    "\n",
    "In \\[15\\]:\n",
    "\n",
    "    # Get summary statistics\n",
    "    model.summary()\n",
    "\n",
    "Out\\[15\\]:\n",
    "\n",
    "|                   |                  |                     |           |\n",
    "|-------------------|------------------|---------------------|-----------|\n",
    "| Dep. Variable:    | log_price        | R-squared:          | 0.026     |\n",
    "| Model:            | OLS              | Adj. R-squared:     | 0.026     |\n",
    "| Method:           | Least Squares    | F-statistic:        | 265.0     |\n",
    "| Date:             | Wed, 10 Jan 2024 | Prob (F-statistic): | 3.61e-225 |\n",
    "| Time:             | 23:44:58         | Log-Likelihood:     | -56182.   |\n",
    "| No. Observations: | 39840            | AIC:                | 1.124e+05 |\n",
    "| Df Residuals:     | 39835            | BIC:                | 1.124e+05 |\n",
    "| Df Model:         | 4                |                     |           |\n",
    "| Covariance Type:  | nonrobust        |                     |           |\n",
    "\n",
    "OLS Regression Results\n",
    "\n",
    "|                 |         |         |         |          |         |         |\n",
    "|-----------------|---------|---------|---------|----------|---------|---------|\n",
    "|                 | coef    | std err | t       | P\\>\\|t\\| | \\[0.025 | 0.975\\] |\n",
    "| Intercept       | 7.6169  | 0.012   | 632.421 | 0.000    | 7.593   | 7.641   |\n",
    "| C(color)\\[T.E\\] | -0.0375 | 0.016   | -2.394  | 0.017    | -0.068  | -0.007  |\n",
    "| C(color)\\[T.F\\] | 0.1455  | 0.016   | 9.240   | 0.000    | 0.115   | 0.176   |\n",
    "| C(color)\\[T.H\\] | 0.3015  | 0.016   | 18.579  | 0.000    | 0.270   | 0.333   |\n",
    "| C(color)\\[T.I\\] | 0.4061  | 0.018   | 22.479  | 0.000    | 0.371   | 0.441   |\n",
    "\n",
    "|                |          |                   |          |\n",
    "|----------------|----------|-------------------|----------|\n",
    "| Omnibus:       | 7112.992 | Durbin-Watson:    | 0.065    |\n",
    "| Prob(Omnibus): | 0.000    | Jarque-Bera (JB): | 1542.881 |\n",
    "| Skew:          | 0.079    | Prob(JB):         | 0.00     |\n",
    "| Kurtosis:      | 2.049    | Cond. No.         | 6.32     |\n",
    "\n",
    "  \n",
    "  \n",
    "Warnings:  \n",
    "\\[1\\] Standard Errors assume that the covariance matrix of the errors is\n",
    "correctly specified.\n",
    "\n",
    "Based on the model summary table, the color grades' associated beta\n",
    "coefficients all have a p-value of less than 0.05 (check the `P>|t|`\n",
    "column). But we can't be sure if there is a significant price difference\n",
    "between the various color grades. This is where one-way ANOVA comes in.\n",
    "\n",
    "First, we have to state our null and alternative hypotheses:\n",
    "\n",
    "#### Null Hypothesis<a href=\"#Null-Hypothesis\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "\\$\\$H_0: price_D=price_E=price_F=price_H=price_I\\$\\$\n",
    "\n",
    "There is no difference in the price of diamonds based on color grade.\n",
    "\n",
    "#### Alternative Hypothesis<a href=\"#Alternative-Hypothesis\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "\\$\\$H_1: \\text{Not } price_D=price_E=price_F=price_H=price_I\\$\\$\n",
    "\n",
    "There is a difference in the price of diamonds based on color grade.\n",
    "\n",
    "In \\[16\\]:\n",
    "\n",
    "    # Run one-way ANOVA\n",
    "    sm.stats.anova_lm(model, typ = 2)\n",
    "\n",
    "Out\\[16\\]:\n",
    "\n",
    "|          | sum_sq       | df      | F          | PR(\\>F)       |\n",
    "|----------|--------------|---------|------------|---------------|\n",
    "| C(color) | 1041.690290  | 4.0     | 264.987395 | 3.609774e-225 |\n",
    "| Residual | 39148.779822 | 39835.0 | NaN        | NaN           |\n",
    "\n",
    "In \\[17\\]:\n",
    "\n",
    "    sm.stats.anova_lm(model, typ = 1)\n",
    "\n",
    "Out\\[17\\]:\n",
    "\n",
    "|          | df      | sum_sq       | mean_sq    | F          | PR(\\>F)       |\n",
    "|----------|---------|--------------|------------|------------|---------------|\n",
    "| C(color) | 4.0     | 1041.690290  | 260.422572 | 264.987395 | 3.609774e-225 |\n",
    "| Residual | 39835.0 | 39148.779822 | 0.982773   | NaN        | NaN           |\n",
    "\n",
    "In \\[18\\]:\n",
    "\n",
    "    sm.stats.anova_lm(model, typ = 3)\n",
    "\n",
    "Out\\[18\\]:\n",
    "\n",
    "|           | sum_sq        | df      | F             | PR(\\>F)       |\n",
    "|-----------|---------------|---------|---------------|---------------|\n",
    "| Intercept | 393066.804852 | 1.0     | 399956.684283 | 0.000000e+00  |\n",
    "| C(color)  | 1041.690290   | 4.0     | 264.987395    | 3.609774e-225 |\n",
    "| Residual  | 39148.779822  | 39835.0 | NaN           | NaN           |\n",
    "\n",
    "We use the `anova_lm()` function from the `statsmodels.stats` package.\n",
    "As noted previously, the function requires a fitted regression model,\n",
    "and for us to specify the type of ANOVA: 1, 2, or 3. You can review the\n",
    "[statsmodels\n",
    "documentation](https://www.statsmodels.org/dev/generated/statsmodels.stats.anova.anova_lm.html)\n",
    "to learn more, as well as to [this\n",
    "article](https://www.r-bloggers.com/2011/03/anova-%e2%80%93-type-iiiiii-ss-explained/)\n",
    "and [this explanation on\n",
    "StackExchange](https://stats.stackexchange.com/questions/20452/how-to-interpret-type-i-type-ii-and-type-iii-anova-and-manova).\n",
    "Since the p-value (column `PR(>F)`) is very small, we can reject the\n",
    "null hypothesis that the mean of the price is the same for all diamond\n",
    "color grades.\n",
    "\n",
    "**Technical note:** The type of an ANOVA and the number of ways of an\n",
    "ANOVA are two distinct concepts: \"type\" (`typ` in\n",
    "`statsmodels.stats.anova.anova_lm()`) refers to how the sums of squares\n",
    "(these quantities are the building blocks for ANOVA) are calculated,\n",
    "while \"K-way\" means that there are K categorical factors in the\n",
    "analysis.\n",
    "\n",
    "## Data cleaning II (not shown in video)<a href=\"#Data-cleaning-II-(not-shown-in-video)\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "In this part of the notebook, we will prepare a second dataset so we can\n",
    "perform a two-way ANOVA, which requires two categorical variables. We\n",
    "will start with the same diamonds dataset from the `seaborn` package.\n",
    "\n",
    "In \\[19\\]:\n",
    "\n",
    "    # Import diamonds data set from seaborn package\n",
    "    diamonds = sns.load_dataset(\"diamonds\", cache=False)\n",
    "\n",
    "In \\[20\\]:\n",
    "\n",
    "    # Examine first 5 rows of data set\n",
    "    diamonds.head()\n",
    "\n",
    "Out\\[20\\]:\n",
    "\n",
    "|     | carat | cut     | color | clarity | depth | table | price | x    | y    | z    |\n",
    "|-----|-------|---------|-------|---------|-------|-------|-------|------|------|------|\n",
    "| 0   | 0.23  | Ideal   | E     | SI2     | 61.5  | 55.0  | 326   | 3.95 | 3.98 | 2.43 |\n",
    "| 1   | 0.21  | Premium | E     | SI1     | 59.8  | 61.0  | 326   | 3.89 | 3.84 | 2.31 |\n",
    "| 2   | 0.23  | Good    | E     | VS1     | 56.9  | 65.0  | 327   | 4.05 | 4.07 | 2.31 |\n",
    "| 3   | 0.29  | Premium | I     | VS2     | 62.4  | 58.0  | 334   | 4.20 | 4.23 | 2.63 |\n",
    "| 4   | 0.31  | Good    | J     | SI2     | 63.3  | 58.0  | 335   | 4.34 | 4.35 | 2.75 |\n",
    "\n",
    "Below, we go through a very similar process as above. We start by\n",
    "selecting the columns of interest: `color`, `cut`, and `price`. Then, we\n",
    "subset only for certain color grades, and remove the dropped colors from\n",
    "the list of categories using the `remove_categories()` function.\n",
    "\n",
    "Next, we subset for specific diamond cuts: `Ideal`, `Premium`, and\n",
    "`Very Good`, and remove the dropped cuts from the list of categories.\n",
    "\n",
    "Next, we remove rows with missing data, and reset the index.\n",
    "\n",
    "Lastly, we add in a column for the logarithm of the price.\n",
    "\n",
    "In \\[21\\]:\n",
    "\n",
    "    # Subset for color, cut, price columns\n",
    "    diamonds2 = diamonds[[\"color\",\"cut\",\"price\"]]\n",
    "\n",
    "    # Only include colorless diamonds\n",
    "    diamonds2 = diamonds2[diamonds2[\"color\"].isin([\"E\",\"F\",\"H\",\"D\",\"I\"])]\n",
    "\n",
    "    # Drop removed colors, G and J\n",
    "    diamonds2.color = diamonds2.color.cat.remove_categories([\"G\",\"J\"])\n",
    "\n",
    "    # Only include ideal, premium, and very good diamonds\n",
    "    diamonds2 = diamonds2[diamonds2[\"cut\"].isin([\"Ideal\",\"Premium\",\"Very Good\"])]\n",
    "\n",
    "    # Drop removed cuts\n",
    "    diamonds2.cut = diamonds2.cut.cat.remove_categories([\"Good\",\"Fair\"])\n",
    "\n",
    "    # Drop NaNs\n",
    "    diamonds2.dropna(inplace = True)\n",
    "\n",
    "    # Reset index\n",
    "    diamonds2.reset_index(inplace = True, drop = True)\n",
    "\n",
    "    # Add column for logarithm of price\n",
    "    diamonds2.insert(3,\"log_price\",[math.log(price) for price in diamonds2[\"price\"]])\n",
    "\n",
    "In \\[22\\]:\n",
    "\n",
    "    # Examine the data set\n",
    "    diamonds2.head()\n",
    "\n",
    "Out\\[22\\]:\n",
    "\n",
    "|     | color | cut       | price | log_price |\n",
    "|-----|-------|-----------|-------|-----------|\n",
    "| 0   | E     | Ideal     | 326   | 5.786897  |\n",
    "| 1   | E     | Premium   | 326   | 5.786897  |\n",
    "| 2   | I     | Premium   | 334   | 5.811141  |\n",
    "| 3   | I     | Very Good | 336   | 5.817111  |\n",
    "| 4   | H     | Very Good | 337   | 5.820083  |\n",
    "\n",
    "We save the dataset as a .csv file again using the `to_csv()` function,\n",
    "just as above.\n",
    "\n",
    "In \\[23\\]:\n",
    "\n",
    "    # Save as diamonds2.csv\n",
    "    diamonds2.to_csv('diamonds2.csv',index=False,header=list(diamonds2.columns))\n",
    "\n",
    "## Two-Way ANOVA<a href=\"#Two-Way-ANOVA\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "Now we can load in the dataset we just created using the `read_csv()`\n",
    "function from `pandas`.\n",
    "\n",
    "In \\[24\\]:\n",
    "\n",
    "    # Load the data set\n",
    "    diamonds2 = pd.read_csv(\"diamonds2.csv\")\n",
    "\n",
    "In \\[25\\]:\n",
    "\n",
    "    # Examine the first 5 rows of the data set\n",
    "    diamonds2.head()\n",
    "\n",
    "Out\\[25\\]:\n",
    "\n",
    "|     | color | cut       | price | log_price |\n",
    "|-----|-------|-----------|-------|-----------|\n",
    "| 0   | E     | Ideal     | 326   | 5.786897  |\n",
    "| 1   | E     | Premium   | 326   | 5.786897  |\n",
    "| 2   | I     | Premium   | 334   | 5.811141  |\n",
    "| 3   | I     | Very Good | 336   | 5.817111  |\n",
    "| 4   | H     | Very Good | 337   | 5.820083  |\n",
    "\n",
    "Then we'll create a multiple linear regression model using the `ols()`\n",
    "function, fit the model to the data, and get the summary statistics.\n",
    "\n",
    "**Note:** This regression model includes two categorical X variables:\n",
    "`color` and `cut`, and a variable to account for the interaction between\n",
    "`color` and `cut`. The interaction is denoted using the `:` symbol.\n",
    "\n",
    "In \\[26\\]:\n",
    "\n",
    "    # Construct a multiple linear regression with an interaction term between color and cut\n",
    "    model2 = ols(formula = \"log_price ~ C(color) + C(cut) + C(color):C(cut)\", data = diamonds2).fit()\n",
    "\n",
    "In \\[27\\]:\n",
    "\n",
    "    # Get summary statistics\n",
    "    model2.summary()\n",
    "\n",
    "Out\\[27\\]:\n",
    "\n",
    "|                   |                  |                     |           |\n",
    "|-------------------|------------------|---------------------|-----------|\n",
    "| Dep. Variable:    | log_price        | R-squared:          | 0.046     |\n",
    "| Model:            | OLS              | Adj. R-squared:     | 0.045     |\n",
    "| Method:           | Least Squares    | F-statistic:        | 119.5     |\n",
    "| Date:             | Wed, 10 Jan 2024 | Prob (F-statistic): | 0.00      |\n",
    "| Time:             | 23:44:59         | Log-Likelihood:     | -49159.   |\n",
    "| No. Observations: | 34935            | AIC:                | 9.835e+04 |\n",
    "| Df Residuals:     | 34920            | BIC:                | 9.847e+04 |\n",
    "| Df Model:         | 14               |                     |           |\n",
    "| Covariance Type:  | nonrobust        |                     |           |\n",
    "\n",
    "OLS Regression Results\n",
    "\n",
    "|                                       |         |         |         |          |         |         |\n",
    "|---------------------------------------|---------|---------|---------|----------|---------|---------|\n",
    "|                                       | coef    | std err | t       | P\\>\\|t\\| | \\[0.025 | 0.975\\] |\n",
    "| Intercept                             | 7.4567  | 0.019   | 401.583 | 0.000    | 7.420   | 7.493   |\n",
    "| C(color)\\[T.E\\]                       | -0.0056 | 0.024   | -0.231  | 0.817    | -0.053  | 0.042   |\n",
    "| C(color)\\[T.F\\]                       | 0.1755  | 0.024   | 7.166   | 0.000    | 0.128   | 0.224   |\n",
    "| C(color)\\[T.H\\]                       | 0.2756  | 0.026   | 10.739  | 0.000    | 0.225   | 0.326   |\n",
    "| C(color)\\[T.I\\]                       | 0.3787  | 0.028   | 13.294  | 0.000    | 0.323   | 0.435   |\n",
    "| C(cut)\\[T.Premium\\]                   | 0.2828  | 0.031   | 9.153   | 0.000    | 0.222   | 0.343   |\n",
    "| C(cut)\\[T.Very Good\\]                 | 0.2295  | 0.031   | 7.290   | 0.000    | 0.168   | 0.291   |\n",
    "| C(color)\\[T.E\\]:C(cut)\\[T.Premium\\]   | -0.0322 | 0.040   | -0.800  | 0.424    | -0.111  | 0.047   |\n",
    "| C(color)\\[T.F\\]:C(cut)\\[T.Premium\\]   | 0.0313  | 0.040   | 0.775   | 0.438    | -0.048  | 0.110   |\n",
    "| C(color)\\[T.H\\]:C(cut)\\[T.Premium\\]   | 0.0947  | 0.041   | 2.308   | 0.021    | 0.014   | 0.175   |\n",
    "| C(color)\\[T.I\\]:C(cut)\\[T.Premium\\]   | 0.0841  | 0.046   | 1.832   | 0.067    | -0.006  | 0.174   |\n",
    "| C(color)\\[T.E\\]:C(cut)\\[T.Very Good\\] | -0.0931 | 0.041   | -2.294  | 0.022    | -0.173  | -0.014  |\n",
    "| C(color)\\[T.F\\]:C(cut)\\[T.Very Good\\] | -0.1013 | 0.041   | -2.459  | 0.014    | -0.182  | -0.021  |\n",
    "| C(color)\\[T.H\\]:C(cut)\\[T.Very Good\\] | -0.0247 | 0.043   | -0.576  | 0.564    | -0.109  | 0.059   |\n",
    "| C(color)\\[T.I\\]:C(cut)\\[T.Very Good\\] | 0.0359  | 0.048   | 0.753   | 0.451    | -0.057  | 0.129   |\n",
    "\n",
    "|                |          |                   |           |\n",
    "|----------------|----------|-------------------|-----------|\n",
    "| Omnibus:       | 4862.888 | Durbin-Watson:    | 0.101     |\n",
    "| Prob(Omnibus): | 0.000    | Jarque-Bera (JB): | 1246.556  |\n",
    "| Skew:          | 0.108    | Prob(JB):         | 2.06e-271 |\n",
    "| Kurtosis:      | 2.100    | Cond. No.         | 20.8      |\n",
    "\n",
    "  \n",
    "  \n",
    "Warnings:  \n",
    "\\[1\\] Standard Errors assume that the covariance matrix of the errors is\n",
    "correctly specified.\n",
    "\n",
    "Based on the model summary table, many of the color grades' and cuts'\n",
    "associated beta coefficients have a p-value of less than 0.05 (check the\n",
    "`P>|t|` column). Additionally, some of the interactions also seem\n",
    "statistically significant. We'll use a two-way ANOVA to examine further\n",
    "the relationships between price and the two categories of color grade\n",
    "and cut.\n",
    "\n",
    "First, we have to state our three pairs of null and alternative\n",
    "hypotheses:\n",
    "\n",
    "#### **Null Hypothesis (Color)**<a href=\"#Null-Hypothesis-(Color)\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "\\$\\$H_0: price_D=price_E=price_F=price_H=price_I\\$\\$\n",
    "\n",
    "There is no difference in the price of diamonds based on color.\n",
    "\n",
    "#### **Alternative Hypothesis (Color)**<a href=\"#Alternative-Hypothesis-(Color)\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "\\$\\$H_1: \\text{Not } price_D=price_E=price_F=price_H=price_I\\$\\$\n",
    "\n",
    "There is a difference in the price of diamonds based on color.\n",
    "\n",
    "#### **Null Hypothesis (Cut)**<a href=\"#Null-Hypothesis-(Cut)\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "\\$\\$H_0: price\\_{Ideal}=price\\_{Premium}=price\\_{Very \\space Good}\\$\\$\n",
    "\n",
    "There is no difference in the price of diamonds based on cut.\n",
    "\n",
    "#### **Alternative Hypothesis (Cut)**<a href=\"#Alternative-Hypothesis-(Cut)\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "\\$\\$H_1: \\text{Not } price\\_{Ideal}=price\\_{Premium}=price\\_{Very \\space\n",
    "Good}\\$\\$\n",
    "\n",
    "There is a difference in the price of diamonds based on cut.\n",
    "\n",
    "#### **Null Hypothesis (Interaction)**<a href=\"#Null-Hypothesis-(Interaction)\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "\\$\\$H_0: \\text{The effect of color on diamond price is independent of\n",
    "the cut, and vice versa.}\\$\\$\n",
    "\n",
    "#### **Alternative Hypothesis (Interaction)**<a href=\"#Alternative-Hypothesis-(Interaction)\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "\\$\\$H_1: \\text{There is an interaction effect between color and cut on\n",
    "diamond price.}\\$\\$\n",
    "\n",
    "The syntax for a two-way ANOVA is the same as for a one-way ANOVA. We\n",
    "will continue to use the `anova_lm()` function from `statsmodels.stats`.\n",
    "\n",
    "In \\[28\\]:\n",
    "\n",
    "    # Run two-way ANOVA\n",
    "    sm.stats.anova_lm(model2, typ = 2)\n",
    "\n",
    "Out\\[28\\]:\n",
    "\n",
    "|                 | sum_sq       | df      | F          | PR(\\>F)       |\n",
    "|-----------------|--------------|---------|------------|---------------|\n",
    "| C(color)        | 926.361461   | 4.0     | 237.014783 | 3.481145e-201 |\n",
    "| C(cut)          | 630.641441   | 2.0     | 322.706309 | 1.348511e-139 |\n",
    "| C(color):C(cut) | 27.478611    | 8.0     | 3.515279   | 4.531734e-04  |\n",
    "| Residual        | 34120.806577 | 34920.0 | NaN        | NaN           |\n",
    "\n",
    "In \\[29\\]:\n",
    "\n",
    "    sm.stats.anova_lm(model2, typ = 1)\n",
    "\n",
    "Out\\[29\\]:\n",
    "\n",
    "|                 | df      | sum_sq       | mean_sq    | F          | PR(\\>F)       |\n",
    "|-----------------|---------|--------------|------------|------------|---------------|\n",
    "| C(color)        | 4.0     | 977.195814   | 244.298954 | 250.021037 | 3.747388e-212 |\n",
    "| C(cut)          | 2.0     | 630.641441   | 315.320721 | 322.706309 | 1.348511e-139 |\n",
    "| C(color):C(cut) | 8.0     | 27.478611    | 3.434826   | 3.515279   | 4.531734e-04  |\n",
    "| Residual        | 34920.0 | 34120.806577 | 0.977114   | NaN        | NaN           |\n",
    "\n",
    "In \\[30\\]:\n",
    "\n",
    "    sm.stats.anova_lm(model2, typ = 3)\n",
    "\n",
    "Out\\[30\\]:\n",
    "\n",
    "|                 | sum_sq        | df      | F             | PR(\\>F)      |\n",
    "|-----------------|---------------|---------|---------------|--------------|\n",
    "| Intercept       | 157578.043681 | 1.0     | 161268.910012 | 0.000000e+00 |\n",
    "| C(color)        | 319.145817    | 4.0     | 81.655250     | 4.134649e-69 |\n",
    "| C(cut)          | 100.144107    | 2.0     | 51.244864     | 5.987341e-23 |\n",
    "| C(color):C(cut) | 27.478611     | 8.0     | 3.515279      | 4.531734e-04 |\n",
    "| Residual        | 34120.806577  | 34920.0 | NaN           | NaN          |\n",
    "\n",
    "Since all of the p-values (column `PR(>F)`) are very small, we can\n",
    "reject all three null hypotheses.\n",
    "\n",
    "# ANOVA post hoc test (Part II)<a href=\"#ANOVA-post-hoc-test-(Part-II)\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "This part of the notebook contains all of the code that will be\n",
    "presented in the second part of this section in the course. The focus is\n",
    "on post hoc tests after one-way ANOVA using the `statsmodels` package in\n",
    "Python.\n",
    "\n",
    "Recall the following definitions:\n",
    "\n",
    "-   **One-way ANOVA:** Compares the means of one continuous dependent\n",
    "    variable based on three or more groups of one categorical variable.\n",
    "-   **Post hoc test:** Performs a pairwise comparison between all\n",
    "    available groups while controlling for the error rate.\n",
    "\n",
    "**Note:** Recall that if we run multiple hypothesis tests all with a 95%\n",
    "confidence level, there is an increasing chance of a false positive, or\n",
    "falsely rejecting the null hypothesis. The post hoc test will control\n",
    "for this, and allows us to run many hypothesis tests while remaining\n",
    "confident with the accuracy of the results. Otherwise, be very careful\n",
    "when running multiple hypothesis tests.\n",
    "\n",
    "## Relevant Imports<a href=\"#Relevant-Imports\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "We'll start by importing the `statsmodels` package and the `ols`\n",
    "function so we can construct a simple linear regression model. Next, we\n",
    "load in the dataset from the one-way ANOVA.\n",
    "\n",
    "**Note:** Running a post hoc test on two-way ANOVA is a bit more\n",
    "advanced and outside the scope of this program, but feel free to explore\n",
    "that on your own.\n",
    "\n",
    "In \\[31\\]:\n",
    "\n",
    "    # Import statsmodels package and ols function\n",
    "    import statsmodels.api as sm\n",
    "    from statsmodels.formula.api import ols\n",
    "\n",
    "In \\[32\\]:\n",
    "\n",
    "    # Load in the data set from one-way ANOVA\n",
    "    diamonds = pd.read_csv(\"diamonds.csv\")\n",
    "\n",
    "## One-way ANOVA<a href=\"#One-way-ANOVA\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "Here we follow the same steps as above:\n",
    "\n",
    "1.  Build a simple linear regression model\n",
    "2.  Check the results\n",
    "3.  Run one-way ANOVA\n",
    "\n",
    "In \\[33\\]:\n",
    "\n",
    "    # Construct simple linear regression model, and fit the model\n",
    "    model = ols(formula = \"log_price ~ C(color)\", data = diamonds).fit()\n",
    "\n",
    "In \\[34\\]:\n",
    "\n",
    "    # Get summary statistics\n",
    "    model.summary()\n",
    "\n",
    "Out\\[34\\]:\n",
    "\n",
    "|                   |                  |                     |           |\n",
    "|-------------------|------------------|---------------------|-----------|\n",
    "| Dep. Variable:    | log_price        | R-squared:          | 0.026     |\n",
    "| Model:            | OLS              | Adj. R-squared:     | 0.026     |\n",
    "| Method:           | Least Squares    | F-statistic:        | 265.0     |\n",
    "| Date:             | Wed, 10 Jan 2024 | Prob (F-statistic): | 3.61e-225 |\n",
    "| Time:             | 23:45:00         | Log-Likelihood:     | -56182.   |\n",
    "| No. Observations: | 39840            | AIC:                | 1.124e+05 |\n",
    "| Df Residuals:     | 39835            | BIC:                | 1.124e+05 |\n",
    "| Df Model:         | 4                |                     |           |\n",
    "| Covariance Type:  | nonrobust        |                     |           |\n",
    "\n",
    "OLS Regression Results\n",
    "\n",
    "|                 |         |         |         |          |         |         |\n",
    "|-----------------|---------|---------|---------|----------|---------|---------|\n",
    "|                 | coef    | std err | t       | P\\>\\|t\\| | \\[0.025 | 0.975\\] |\n",
    "| Intercept       | 7.6169  | 0.012   | 632.421 | 0.000    | 7.593   | 7.641   |\n",
    "| C(color)\\[T.E\\] | -0.0375 | 0.016   | -2.394  | 0.017    | -0.068  | -0.007  |\n",
    "| C(color)\\[T.F\\] | 0.1455  | 0.016   | 9.240   | 0.000    | 0.115   | 0.176   |\n",
    "| C(color)\\[T.H\\] | 0.3015  | 0.016   | 18.579  | 0.000    | 0.270   | 0.333   |\n",
    "| C(color)\\[T.I\\] | 0.4061  | 0.018   | 22.479  | 0.000    | 0.371   | 0.441   |\n",
    "\n",
    "|                |          |                   |          |\n",
    "|----------------|----------|-------------------|----------|\n",
    "| Omnibus:       | 7112.992 | Durbin-Watson:    | 0.065    |\n",
    "| Prob(Omnibus): | 0.000    | Jarque-Bera (JB): | 1542.881 |\n",
    "| Skew:          | 0.079    | Prob(JB):         | 0.00     |\n",
    "| Kurtosis:      | 2.049    | Cond. No.         | 6.32     |\n",
    "\n",
    "  \n",
    "  \n",
    "Warnings:  \n",
    "\\[1\\] Standard Errors assume that the covariance matrix of the errors is\n",
    "correctly specified.\n",
    "\n",
    "Now that we have reconstructed the simple linear regression model, we\n",
    "can re-run the ANOVA.\n",
    "\n",
    "In \\[35\\]:\n",
    "\n",
    "    # Run one-way ANOVA\n",
    "    sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "Out\\[35\\]:\n",
    "\n",
    "|          | sum_sq       | df      | F          | PR(\\>F)       |\n",
    "|----------|--------------|---------|------------|---------------|\n",
    "| C(color) | 1041.690290  | 4.0     | 264.987395 | 3.609774e-225 |\n",
    "| Residual | 39148.779822 | 39835.0 | NaN        | NaN           |\n",
    "\n",
    "Since the p-value is very small and we can reject the null hypothesis\n",
    "that the mean price is the same for all diamond color grades, we can\n",
    "continue on to run a post hoc test. The post hoc test is useful because\n",
    "the one-way ANOVA does not tell us which colors are associated with\n",
    "different prices. The post hoc test will give us more information.\n",
    "\n",
    "## Post hoc test<a href=\"#Post-hoc-test\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "There are many post hoc tests that can be run. One of the most common\n",
    "ANOVA post hoc tests is the **Tukey's HSD (honestly significantly\n",
    "different) test**. We can import the `pairwise_tukeyhsd()` function from\n",
    "the `statsmodels` package to run the test.\n",
    "\n",
    "In \\[36\\]:\n",
    "\n",
    "    # Import Tukey's HSD function\n",
    "    from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "Then we can run the test. The `endog` variable specifies which variable\n",
    "is being compared across groups, which is `log_price` in this case. Then\n",
    "the `groups` variables indicates which variable holds the groups we're\n",
    "comparing, which is `color`. `alpha` tells the function the significance\n",
    "or confidence level, which we'll set to `0.05`. We'll aim for the\n",
    "typical 95% confidence level.\n",
    "\n",
    "In \\[37\\]:\n",
    "\n",
    "    # Run Tukey's HSD post hoc test for one-way ANOVA\n",
    "    tukey_oneway = pairwise_tukeyhsd(endog = diamonds[\"log_price\"], groups = diamonds[\"color\"], alpha = 0.05)\n",
    "\n",
    "Lastly, we get the results of the test.\n",
    "\n",
    "In \\[38\\]:\n",
    "\n",
    "    # Get results (pairwise comparisons)\n",
    "    tukey_oneway.summary()\n",
    "\n",
    "Out\\[38\\]:\n",
    "\n",
    "| group1 | group2 | meandiff | p-adj  | lower   | upper  | reject |\n",
    "|--------|--------|----------|--------|---------|--------|--------|\n",
    "| D      | E      | -0.0375  | 0.1171 | -0.0802 | 0.0052 | False  |\n",
    "| D      | F      | 0.1455   | 0.001  | 0.1026  | 0.1885 | True   |\n",
    "| D      | H      | 0.3015   | 0.001  | 0.2573  | 0.3458 | True   |\n",
    "| D      | I      | 0.4061   | 0.001  | 0.3568  | 0.4553 | True   |\n",
    "| E      | F      | 0.183    | 0.001  | 0.1441  | 0.2219 | True   |\n",
    "| E      | H      | 0.339    | 0.001  | 0.2987  | 0.3794 | True   |\n",
    "| E      | I      | 0.4436   | 0.001  | 0.3978  | 0.4893 | True   |\n",
    "| F      | H      | 0.156    | 0.001  | 0.1154  | 0.1966 | True   |\n",
    "| F      | I      | 0.2605   | 0.001  | 0.2145  | 0.3065 | True   |\n",
    "| H      | I      | 0.1045   | 0.001  | 0.0573  | 0.1517 | True   |\n",
    "\n",
    "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
    "\n",
    "Each row represents a pariwise comparison between the prices of two\n",
    "diamond color grades. The `reject` column tells us which null hypotheses\n",
    "we can reject. Based on the values in that column, we can reject each\n",
    "null hypothesis, except when comparing D and E color diamonds. We cannot\n",
    "reject the null hypothesis that the diamond price of D and E color\n",
    "diamonds are the same.\n",
    "\n",
    "#### **Test 1: D vs. E**<a href=\"#Test-1:-D-vs.-E\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "\\$H_0: price_D=price_E\\$\n",
    "\n",
    "The price of D and E color grade diamonds are the same.\n",
    "\n",
    "\\$H_1: price_D \\neq price_E\\$\n",
    "\n",
    "The price of D and E color grade diamonds are not the same.\n",
    "\n",
    "**Result:** We *cannot* reject the null hypothesis that the price of D\n",
    "and E color grade diamonds are the same.\n",
    "\n",
    "#### **Test 2: D vs. F**<a href=\"#Test-2:-D-vs.-F\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "\\$H_0: price_D=price_F\\$\n",
    "\n",
    "The price of D and F color grade diamonds are the same.\n",
    "\n",
    "\\$H_1: price_D \\neq price_F\\$\n",
    "\n",
    "The price of D and F color grade diamonds are not the same.\n",
    "\n",
    "**Result:** We *can* reject the null hypothesis that the price of D and\n",
    "F color grade diamonds are the same.\n",
    "\n",
    "#### **Test 3: D vs. H**<a href=\"#Test-3:-D-vs.-H\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "\\$H_0: price_D=price_H\\$\n",
    "\n",
    "The price of D and H color grade diamonds are the same.\n",
    "\n",
    "\\$H_1: price_D \\neq price_H\\$\n",
    "\n",
    "The price of D and H color grade diamonds are not the same.\n",
    "\n",
    "**Result:** We *can* reject the null hypothesis that the price of D and\n",
    "H color grade diamonds are the same.\n",
    "\n",
    "#### **Test 4: D vs. I**<a href=\"#Test-4:-D-vs.-I\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "\\$H_0: price_D=price_I\\$\n",
    "\n",
    "The price of D and I color grade diamonds are the same.\n",
    "\n",
    "\\$H_1: price_D \\neq price_I\\$\n",
    "\n",
    "The price of D and I color grade diamonds are not the same.\n",
    "\n",
    "**Result:** We *can* reject the null hypothesis that the price of D and\n",
    "I color grade diamonds are the same.\n",
    "\n",
    "#### **Test 5: E vs. F**<a href=\"#Test-5:-E-vs.-F\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "\\$H_0: price_E=price_F\\$\n",
    "\n",
    "The price of E and F color grade diamonds are the same.\n",
    "\n",
    "\\$H_1: price_E \\neq price_F\\$\n",
    "\n",
    "The price of E and F color grade diamonds are not the same.\n",
    "\n",
    "**Result:** We *can* reject the null hypothesis that the price of E and\n",
    "F color grade diamonds are the same.\n",
    "\n",
    "#### **Test 6: E vs. H**<a href=\"#Test-6:-E-vs.-H\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "\\$H_0: price_E=price_H\\$\n",
    "\n",
    "The price of E and H color grade diamonds are the same.\n",
    "\n",
    "\\$H_1: price_E \\neq price_H\\$\n",
    "\n",
    "The price of E and H color grade diamonds are not the same.\n",
    "\n",
    "**Result:** We *can* reject the null hypothesis that the price of E and\n",
    "H color grade diamonds are the same.\n",
    "\n",
    "#### **Test 7: E vs. I**<a href=\"#Test-7:-E-vs.-I\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "\\$H_0: price_E=price_I\\$\n",
    "\n",
    "The price of E and I color grade diamonds are the same.\n",
    "\n",
    "\\$H_1: price_E \\neq price_I\\$\n",
    "\n",
    "The price of E and I color grade diamonds are not the same.\n",
    "\n",
    "**Result:** We *can* reject the null hypothesis that the price of E and\n",
    "I color grade diamonds are the same.\n",
    "\n",
    "#### **Test 8: F vs. H**<a href=\"#Test-8:-F-vs.-H\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "\\$H_0: price_F=price_H\\$\n",
    "\n",
    "The price of F and H color grade diamonds are the same.\n",
    "\n",
    "\\$H_1: price_F \\neq price_H\\$\n",
    "\n",
    "The price of F and H color grade diamonds are not the same.\n",
    "\n",
    "**Result:** We *can* reject the null hypothesis that the price of F and\n",
    "H color grade diamonds are the same.\n",
    "\n",
    "#### **Test 9: F vs. I**<a href=\"#Test-9:-F-vs.-I\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "\\$H_0: price_F=price_I\\$\n",
    "\n",
    "The price of F and I color grade diamonds are the same.\n",
    "\n",
    "\\$H_1: price_F \\neq price_I\\$\n",
    "\n",
    "The price of F and I color grade diamonds are not the same.\n",
    "\n",
    "**Result:** We *can* reject the null hypothesis that the price of F and\n",
    "I color grade diamonds are the same.\n",
    "\n",
    "#### **Test 10: H vs. I**<a href=\"#Test-10:-H-vs.-I\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "\\$H_0: price_H=price_I\\$\n",
    "\n",
    "The price of H and I color grade diamonds are the same.\n",
    "\n",
    "\\$H_1: price_H \\neq price_I\\$\n",
    "\n",
    "The price of H and I color grade diamonds are not the same.\n",
    "\n",
    "**Result:** We *can* reject the null hypothesis that the price of H and\n",
    "I color grade diamonds are the same.\n",
    "\n",
    "**Congratulations!** You've completed this lab. However, you may not\n",
    "notice a green check mark next to this item on Coursera's platform.\n",
    "Please continue your progress regardless of the check mark. Just click\n",
    "on the \"save\" icon at the top of this notebook to ensure your work has\n",
    "been logged.\n",
    "\n",
    "You now understand how to run a one-way and two-way ANOVA test with\n",
    "Python. Going forward, you can start using one-way and two-way ANOVA\n",
    "tests with your own datasets."
   ],
   "id": "42a14256-91c8-446e-92a7-ab6bf11055d3"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
